"""
Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤

Confluence RAG ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì›¹ UIë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os

import gradio as gr
from dotenv import load_dotenv
from rich.console import Console

from rag_search import ConfluenceRAG

load_dotenv()

console = Console()

# RAG ì—”ì§„ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
rag_engine: ConfluenceRAG | None = None


def load_rag_system() -> ConfluenceRAG | None:
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”

    ConfluenceRAG ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ì „ì—­ ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
    ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        ConfluenceRAG ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None
    """
    global rag_engine

    if rag_engine is not None:
        return rag_engine

    try:
        console.print("[blue]RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...[/blue]")
        rag_engine = ConfluenceRAG()
        console.print("[green]RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ[/green]")
        return rag_engine

    except FileNotFoundError:
        console.print("[red]ë²¡í„° DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.[/red]")
        return None

    except ConnectionError:
        console.print("[red]Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.[/red]")
        return None

    except Exception as e:
        console.print(f"[red]RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}[/red]")
        return None


def search_interface(query: str) -> str:
    """ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ í•¸ë“¤ëŸ¬

    Gradio UIì—ì„œ í˜¸ì¶œë˜ëŠ” ë©”ì¸ ê²€ìƒ‰ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    ì…ë ¥ ê²€ì¦, RAG ê²€ìƒ‰, ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸ í…ìŠ¤íŠ¸

    Returns:
        Markdown í˜•ì‹ì˜ ì‘ë‹µ ë¬¸ìì—´
    """
    # --- ì…ë ¥ ê²€ì¦ ---
    if not query or not query.strip():
        return "âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

    query = query.strip()

    if len(query) > 500:
        return "âš ï¸ ì§ˆë¬¸ì€ 500ì ì´ë‚´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”."

    if len(query) < 2:
        return "âš ï¸ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."

    # --- RAG ì—”ì§„ í™•ì¸ ---
    if rag_engine is None:
        return (
            "## âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜\n\n"
            "RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n"
            "ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”:\n\n"
            "1. **ë²¡í„° DB êµ¬ì¶• ì—¬ë¶€**\n"
            "   ```bash\n"
            "   python preprocess_data.py\n"
            "   python build_vectordb.py\n"
            "   ```\n\n"
            "2. **Ollama ì„œë²„ ì‹¤í–‰ ì—¬ë¶€**\n"
            "   ```bash\n"
            "   ollama serve\n"
            "   ollama pull anpigon/eeve-korean-10.8b\n"
            "   ```"
        )

    # --- RAG ê²€ìƒ‰ ì‹¤í–‰ ---
    try:
        result = rag_engine.search(query)

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
        if not result["answer"].strip():
            return (
                "## ğŸ” ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\n\n"
                "ì…ë ¥í•˜ì‹  ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n"
                "**ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:**\n"
                "- ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš”\n"
                "- ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš”\n"
                "- Confluenceì— ê´€ë ¨ ë¬¸ì„œê°€ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”"
            )

        # ì •ìƒ ì‘ë‹µ í¬ë§·íŒ…
        return rag_engine.format_response(result)

    except ConnectionError:
        return (
            "## âŒ Ollama ì—°ê²° ì‹¤íŒ¨\n\n"
            "Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "```bash\n"
            "ollama serve\n"
            "```\n\n"
            "ì„œë²„ë¥¼ ì‹œì‘í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )

    except Exception as e:
        return (
            "## âŒ ê²€ìƒ‰ ì˜¤ë¥˜\n\n"
            f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: `{e}`\n\n"
            "ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
        )


def create_ui() -> gr.Blocks:
    """Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ ìƒì„±

    Returns:
        Gradio Blocks ì¸ìŠ¤í„´ìŠ¤
    """
    # ì˜ˆì‹œ ì§ˆë¬¸ ëª©ë¡
    examples = [
        ["í”„ë¡œì íŠ¸ ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"],
        ["ê°œë°œ í™˜ê²½ ì„¤ì • ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”"],
        ["ì½”ë“œ ë¦¬ë·° ê°€ì´ë“œë¼ì¸ì´ ìˆë‚˜ìš”?"],
        ["API ì¸ì¦ ë°©ì‹ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"],
        ["ì‹ ê·œ ì…ì‚¬ì ì˜¨ë³´ë”© ì ˆì°¨ê°€ ê¶ê¸ˆí•©ë‹ˆë‹¤"],
    ]

    with gr.Blocks(
        theme=gr.themes.Soft(),
        title="Confluence AI ê²€ìƒ‰",
        css="""
            .main-title { text-align: center; margin-bottom: 0.5em; }
            .sub-desc { text-align: center; color: #666; margin-bottom: 1.5em; }
        """,
    ) as app:

        # --- í—¤ë” ---
        gr.Markdown(
            "<h1 class='main-title'>ğŸ” Confluence AI ê²€ìƒ‰</h1>",
        )
        gr.Markdown(
            "<p class='sub-desc'>"
            "Confluence ë¬¸ì„œë¥¼ AIë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤. "
            "ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."
            "</p>",
        )

        with gr.Row():
            with gr.Column(scale=4):
                # ì§ˆë¬¸ ì…ë ¥
                query_input = gr.Textbox(
                    label="ì§ˆë¬¸",
                    placeholder="ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì§ˆë¬¸í•´ì£¼ì„¸ìš”...",
                    max_lines=3,
                    lines=2,
                )
            with gr.Column(scale=1, min_width=120):
                # ê²€ìƒ‰ ë²„íŠ¼
                search_btn = gr.Button(
                    "ğŸ” ê²€ìƒ‰",
                    variant="primary",
                    size="lg",
                )

        # ë‹µë³€ ì¶œë ¥
        answer_output = gr.Markdown(
            label="ë‹µë³€",
            value="*ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ê²€ìƒ‰ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.*",
        )

        # ì˜ˆì‹œ ì§ˆë¬¸
        gr.Examples(
            examples=examples,
            inputs=query_input,
            label="ì˜ˆì‹œ ì§ˆë¬¸",
        )

        # --- ì´ë²¤íŠ¸ ë°”ì¸ë”© ---
        # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­
        search_btn.click(
            fn=search_interface,
            inputs=query_input,
            outputs=answer_output,
        )

        # Enter í‚¤ë¡œ ê²€ìƒ‰
        query_input.submit(
            fn=search_interface,
            inputs=query_input,
            outputs=answer_output,
        )

        # --- í•˜ë‹¨ ì •ë³´ ---
        gr.Markdown(
            "<hr/>"
            "<p style='text-align:center; color:#999; font-size:0.85em;'>"
            "Confluence RAG ì‹œìŠ¤í…œ | "
            "ChromaDB + Ollama | "
            "ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ê¸°ë°˜"
            "</p>"
        )

    return app


# ============================================
# ë©”ì¸ ì‹¤í–‰
# ============================================
if __name__ == "__main__":
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    load_rag_system()

    # UI ìƒì„± ë° ì‹¤í–‰
    app = create_ui()

    # ì„œë²„ í¬íŠ¸ (.envì—ì„œ ë¡œë“œ, ê¸°ë³¸ê°’ 7860)
    port = int(os.getenv("GRADIO_SERVER_PORT", "7860"))

    console.print(f"\n[bold magenta]===== Confluence AI ê²€ìƒ‰ UI ì‹œì‘ =====[/bold magenta]")
    console.print(f"[green]http://localhost:{port}[/green]\n")

    app.launch(
        server_port=port,
        share=False,
        show_error=True,
    )
